[["index.html", "Préparer ses données avec R et le Tidyverse Chapitre 1 Introduction 1.1 Le parcours de formation 1.2 Objectifs du module 2", " Préparer ses données avec R et le Tidyverse Maël Theulière &amp; Bruno Terseur 28 November 2021 Chapitre 1 Introduction Crédit photographique Sébastien Colas 1.1 Le parcours de formation Ce dispositif de formation vise à faire monter en compétence les agents du MTES (Ministère de la transition écologique) et du MCTRCT (Ministère de la Cohésion des Territoires et des Relations avec les collectivités territoriales) dans le domaine de la science de la donnée avec le logiciel R. Il est conçu pour être déployé à l’échelle nationale par le réseau des CVRH (Centre de Valorisation des Ressources Humaines). Le parcours proposé est structuré en modules de 2 jours chacun. Les deux premiers (ou un niveau équivalent) sont des pré-requis pour suivre les suivants qui sont proposés “à la carte” : Socle : Premier programme en R Socle : Préparation des données Statistiques descriptives Analyse des données multi-dimensionnelles Datavisualisation : Produire des graphiques, des cartes et des tableaux Publications reproductibles avec RMarkdown (à venir) Analyse spatiale (à venir) Big data et optimisation du code (à venir) Applications interactives avec Shiny (à venir) La mise à disposition des supports de formation se fait désormais par la page d’accueil du parcours de formation. Ces supports sont en licence ouverte. Si vous souhaitez accéder aux sources ou aux données mobilisées pendant les formations, il faut directement les télécharger depuis le Github du ministère. Un package d’exercices, {savoirfR} rassemble toutes les données et les consignes d’exercices de ce support de formation Pour vous tenir au courant de l’offre de formation proposée par le réseau des CVRH, consultez la plateforme OUPS (un accès intranet MTES-MCT est nécessaire). Vous pouvez vous y abonner pour recevoir les annonces de formation qui vous intéressent. Pour échanger de l’information, discuter autour de R ou encore faire part de difficultés et trouver ensemble les solutions, il existe deux solutions: S’insrire en envoyant un message vide à l’adresse sympa@developpement-durable.gouv.fr. Rejoindre le fil Ariane #utilisateurs_r 1.2 Objectifs du module 2 Ce module va vous permettre de découvrir un ensemble de méthodes sous R afin de préparer ses données. Préparer ses données sous R, cela veut dire : Savoir les importer dans un environnement R, Mettre ses données dans de bons formats (date, catégorielle) et gérer les données manquantes, Rajouter des variables en fonction de variables existantes, Regrouper des modalités de variables, Joindre des tables entre elles pour obtenir des informations de plusieurs sources, Aggréger des données, Bien définir notre table de travail en fonction des indicateurs à analyser et à leurs dimensions d’analyse. … Bref, tout le travail technique préalable entre la collecte de la donnée et la valorisation proprement dite de ces sources. On estime qu’un scientifique de la donnée passe en général la moitié de son temps à cela. Sous R, comme souvent, il y a plusieurs façons d’aborder cette question. Ce module de formation privilègie l’exploration des packages du framework tidyverse, qui ont l’avantage d’aborder les différentes phases de préparation des données d’une façon intégrée et cohérente, que ce soit entre elles, ou avec d’autres. "],["le-tidyverse.html", "Chapitre 2 Le tidyverse 2.1 Présentation des packages 2.2 Les spécificités du tidyverse 2.3 D’autres approches possibles", " Chapitre 2 Le tidyverse Le tidyverse est un ensemble de packages proposant une syntaxe cohérente pour remplir l’essentiel des traitements propres à la science de la données, de la lecture des données à la valorisation, en passant par la modélisation. Le manifeste du tidyverse comprend 4 principes clefs pour les packages : Utiliser les structures de données existantes : ne pas créer des objets ad hoc ; Utiliser l’opérateur pipe ; S’intègrer dans l’approche de programmation fonctionnelle de R ; Designé pour les être humains : favoriser la facilité d’usage à la performance machine. 2.1 Présentation des packages 2.1.1 Des packages pour lire des données 2.1.1.1 tidyverse {readr} pour les fichiers plats {readxl} pour les fichiers tableur Excel {haven} pour les données stockées sous des formats propriétaires (SAS, SPSS, …) 2.1.1.2 Hors tidyverse {odbc} / {Rposgresql} pour accéder à des données stockées sous forme de base de données {sf} pour lire des données spatiales {rsdmx} pour lire des données sdmx 2.1.2 Des packages pour manipuler des données 2.1.2.1 tidyverse {dplyr} fonctions correspondant à des “verbes” pour manipuler ses données {tidyr} fonctions pour modifier l’agencement de nos tables entre les lignes et les colonnes 2.1.3 Des packages pour nettoyer des données 2.1.3.1 tidyverse {forcats} permet de manipuler les variables de type catégoriel (ou factor en R) {stringr} permet de manipuler des chaînes de caractères {lubridate} permet de manipuler des dates 2.1.3.2 Hors tidyverse {stringi} permet de manipuler des chaînes de caractères {RcppRoll} qui regroupe des opérations fenêtrées ou glissantes 2.2 Les spécificités du tidyverse Quelques spécificités des fonctions de ce framework : Ces packages sont orientés manipulation de dataframes et non de vecteurs En conséquence, on utilise jamais l’indexation des colonnes de tables (le “$”) pour appeler une variable Chaque fonction ne fait qu’une chose et une seule (c’est une opération élémentaire) L’ensemble des fonctions obéissent à la même logique, ce qui permet de simplifier l’apprentissage L’ensemble de ces opérations élémentaires peuvent s’enchaîner à la manière d’un ETL avec le pipe 2.3 D’autres approches possibles Les fonctions que nous allons voir obéissent à une logique intégrée et simple, qui permet des manipulations complexes, à partir du moment ou l’on est capable d’identifier et de sérier chaque opération élémentaire à réaliser. D’autres packages permettent également de réaliser ce type de manipulations. La différence est qu’ils sont souvent dédiés à une tâche spécifique, ce qui rend la cohérence moins évidente lorsque l’on doit réaliser plusieurs opérations. Un autre package propose toutefois une vision intégrée de la sorte : {data.table}. Plusieurs différences sont à noter : {data.table} est plus rapide sur d’importants volumes de données, le code est très succinct. {dplyr} est plus simple à apprendre, le code est plus lisible, il peut s’appliquer à des formats de données multiples, il s’intègre dans un framework global qui va de la lecture des données ({readr}, {readxl}, {haven}…) à leur valorisation ({ggplot2}). "],["bien-commencer.html", "Chapitre 3 Bien commencer 3.1 Créer un projet sous Rstudio pour vous permettre de recencer vos travaux. 3.2 Intégrer vos données 3.3 Créer votre arborescence de projet 3.4 Utilisation du package savoirfR 3.5 Activer les packages nécessaires 3.6 Bien structurer ses projets data", " Chapitre 3 Bien commencer 3.1 Créer un projet sous Rstudio pour vous permettre de recencer vos travaux. Pourquoi travailler avec les projets Rstudio plutôt que les scripts R ? Cela permet la portabilité : le répertoire de travail par défaut d’un projet est le répertoire où est ce projet. Si vous transmettez celui-ci à un collègue, le fait de lancer un programme ne dépend pas de l’arborescence de votre machine. Fini les setwd(\"chemin/qui/marche/uniquement/sur/mon/poste\") ! Toujours sur la portabilité, un projet peut être utilisé avec un outil comme packrat qui va vous intégrer en interne au projet l’ensemble des packages nécessaires au projet. Cela permet donc à votre collègue à qui vous passez votre projet de ne pas avoir à les installer et, surtout, si vous mettez à jour votre environnement R, votre projet restera toujours avec les versions des packages avec lesquelles vous avez fait tourner votre projet à l’époque. Cela évite d’avoir à subir les effets d’une mise à jour importante d’un package qui casserait votre code. Pour activer renv sur un projet, il faut l’installer avec install.packages(\"renv\"). Pour intialiser la sauvegarde des packages employés dans le projet, il faut utiliser renv::init() Les packages chargés dans le projet sont enregistrés dans un sous-dossier dédié. En cours de travail sur le projet, la commande renv::snapshot() permet de faire une sauvegarde, la commande renv::restore() permet de charger la dernière sauvegarde. En savoir plus sur renv Cela permet de se forcer à travailler en mode projet : on intègre à un seul endroit tout ce qui est lié à un projet : données brutes, données retravaillées, scripts, illustrations, documentations, publications… et donc y compris les packages avec renv. On peut travailler sur plusieurs projets en même temps, Rstudio ouvre autant de sessions que de projets dans ce cas. Les projets Rstudio intègrent une interface avec les outils de gestion de version Git et SVN. Cela veut dire que vous pouvez versionner votre projet et l’héberger simplement comme répertoire sur des plateformes de gestion de code telle que Github ou Gitlab. Pour créer un projet : Cliquez sur Project en haut à droite puis New Project. Cliquez sur New Directory. 3.2 Intégrer vos données Une bonne pratique est de créer un sous répertoire /data pour stocker les données sur lesquelles vous aurez à travailler. Vous pouvez le faire depuis l’explorateur de fichier de votre système d’exploitation ou directement à partir de l’explorateur de fichier de RStudio. Cela marche bien quand on a un seul type de données, mais en général on va avoir à travailler sur des données brutes que l’on va retravailler ensuite et vouloir stocker à part. Si par la suite vous souhaitez avoir des exemples de bonnes pratiques sur comment structurer vos données, vous pouvez vous référer au chapitre data du livre d’Hadley Wickham sur la construction de packages R (tout package R étant aussi un projet !). 3.3 Créer votre arborescence de projet Créer un répertoire /src ou vous mettrez vos scripts R. Créer un répertoire /figures ou vous mettrez vos illustrations issues de R. 3.4 Utilisation du package savoirfR Pour faciliter le déroulé de ce module, l’ensemble des exercices (énoncés, corrigés et données) a été intégré à un package réalisé par le groupe des référents R: savoirfR remotes::install_github(&quot;MTES-MCT/savoirfR&quot;) Pour l’utiliser, il suffit de créer un nouveau projet dans un nouveau répertoire, en sélectionnant le “Project Type” Exercice Parcours R MTES-MCT. Remplissez et sélectionnez le module suivi. 3.5 Activer les packages nécessaires Commencer par rajouter un script dans le répertoire /src à votre projet qui commencera par : activer l’ensemble des packages nécessaires, charger les données dont vous aurez besoin. library(tidyverse) library(lubridate) library(RcppRoll) library(DT) library(readxl) library(dbplyr) library(RPostgreSQL) library(rsdmx) library(sf) library(stringi) sitadel &lt;- read_excel(&quot;extdata/ROES_201702.xls&quot;, sheet = &quot;AUT_REG&quot;, col_types = c (&quot;text&quot;,&quot;text&quot;,&quot;numeric&quot;,&quot;numeric&quot;,&quot;numeric&quot;,&quot;numeric&quot;)) load(file = &quot;extdata/FormationPreparationDesDonnees.RData&quot;) 3.6 Bien structurer ses projets data Plusieurs documents peuvent vous inspirer sur la structuration de vos projets data par la suite. En voici quelques-uns : https://github.com/pavopax/new-project-template https://nicercode.github.io/blog/2013-04-05-projects/ https://www.inwt-statistics.com/read-blog/a-meaningful-file-structure-for-r-projects.html http://projecttemplate.net/architecture.html À partir du moment où quelques grands principes sont respectés (un répertoire pour les données brutes en lecture seule par exemple), le reste est surtout une question d’attirance plus forte pour l’une ou l’autre solution. L’important est de vous tenir ensuite à conserver toujours la même arborescence dans vos projets afin de vous y retrouver plus simplement. "],["lire-des-données.html", "Chapitre 4 Lire des données 4.1 readxl : lire des données Excel 4.2 read_delim : lire des fichiers plats 4.3 Télécharger des données disponibles sur le web 4.4 Lire des fichiers avec une dimension spatiale 4.5 Lire des données sous PostgreSQL 4.6 Lire des données du webservice Insee", " Chapitre 4 Lire des données 4.1 readxl : lire des données Excel La fonction read_excel() permet d’importer les données d’un fichier Excel. On peut spécifier : la feuille, les colonnes, les lignes ou la zone à importer, les lignes à supprimer avant importation, si on souhaite importer la première ligne comme des noms de variables ou non, le format des variables importées, la valeur qui sera interprétée comme étant la valeur manquante. library(readxl) sitadel &lt;- read_excel(&quot;extdata/ROES_201702.xls&quot;, sheet = &quot;AUT_REG&quot;, col_types = c (&quot;text&quot;,&quot;text&quot;,&quot;numeric&quot;,&quot;numeric&quot;,&quot;numeric&quot;,&quot;numeric&quot;)) datatable(sitadel) 4.2 read_delim : lire des fichiers plats La fonction read_delim() permet d’importer les données d’un fichier csv. Elle fonctionne de la même façon que read_excel(). On peut spécifier : le délimiteur de colonne, les lignes à supprimer avant importation, si on souhaite importer la première ligne comme des noms de variables ou non, le locale du fichier, la valeur qui sera interprétée comme étant la valeur manquante. read_csv(), read_csv2() et read_tsv() sont des implémentations prérenseignées de read_delim pour lire des fichiers plats avec séparateurs , ; et tabulaire. 4.3 Télécharger des données disponibles sur le web Parfois, les données que nous exploitons sont disponibles sur le web. Il est possible, directement depuis R, de télécharger ces données et, si nécessaire, de les décompresser (dans le répertoire de travail). Exemple sur les données SEQUOIA de l’ACOSS : url &lt;- &quot;http://www.acoss.fr/files/Donnees_statistiques/SEQUOIA_TRIM_REGION.zip&quot; download.file(url, destfile = &quot;extdata/SEQUOIA_TRIM_REGION.zip&quot;, method = &quot;auto&quot;) unzip(zipfile = &quot;extdata/SEQUOIA_TRIM_REGION.zip&quot;, exdir = &quot;extdata&quot;) SEQUOIA &lt;- read_excel(&quot;extdata/SEQUOIA_TRIM_REGION_BRUT210610.xlsx&quot;, sheet = &quot;PAYS_DE_LA_LOIRE&quot;) datatable(SEQUOIA) 4.4 Lire des fichiers avec une dimension spatiale Le package {sf} (pour simple feature) permet d’importer dans R un fichier ayant une dimension spatiale. Après importation, le fichier est un dataframe avec une variable d’un type nouveau : la géométrie. Deux exemples ici pour lire des données au format shape et geojson. Carte_EPCI_France &lt;- st_read(dsn = &quot;extdata/refgeo2017&quot;, layer = &quot;Contour_epci_2017_region&quot;) plot(Carte_EPCI_France) communes2017 &lt;- st_read(dsn = &quot;extdata/refgeo2017/communes2017.geojson&quot;) plot(communes2017) Le package {sf} contient l’ensemble des fonctions permettant des manipulations sur fichiers géomatiques. On ne traitera pas ici de toutes ces fonctions en détail, se référer pour cela à la documentation du package. A noter que {sf} étant complètement compatible avec les packages du tidyverse, la géométrie se conçoit comme une donnée comme une autre, sur laquelle par exemple on peut réaliser des aggrégations. 4.5 Lire des données sous PostgreSQL Deux approches possibles pour utiliser des données stockées dans une base de données PostgreSQL. Importer toutes ces données dans l’environnement R se connecter à ces données et utiliser un interpréteur permettant de traduire du code R comme une requête SQL. 4.5.1 Lire des données sous PostgreSQL : première approche #Définition du driver drv &lt;- dbDriver(&quot;PostgreSQL&quot;) #Définition de la base de données con &lt;- dbConnect(drv, dbname = &quot;dbname&quot;, host = &quot;ip&quot;, port = numero_du_port, user = &quot;user_name&quot;, password = &quot;pwd&quot;) #Spécification de l&#39;encodage, obligatoire avec Windows postgresqlpqExec(con, &quot;SET client_encoding = &#39;windows-1252&#39;&quot;) #Téléchargement de la table analyse du schéma pesticide parametre &lt;- dbGetQuery(con, &quot;SELECT * FROM pesticides.parametre&quot;) #Téléchargement de données avec dimension spatiale via la fonction st_read du package simple feature station = st_read(con, query = &quot;SELECT * FROM pesticides.station&quot;) On voit que pour importer notre table analyse, on a simplement lancé une requête SQL. On peut bien sûr avec la même fonction lancer n’importe quelle requête sur la base et recueillir le résultat. 4.5.2 Lire des données sous PostgreSQL : seconde approche #définition du driver drv &lt;- dbDriver(&quot;PostgreSQL&quot;) #définition de la base de données con &lt;- dbConnect(drv, dbname = &quot;dbname&quot;, host = &quot;ip&quot;, port = numero_du_port, user = &quot;user_name&quot;, password = &quot;pwd&quot;) #spécification de l&#39;encodage, obligatoire avec windows postgresqlpqExec(con, &quot;SET client_encoding = &#39;windows-1252&#39;&quot;) #téléchargement de la table analyse du schéma pesticide analyse_db &lt;- tbl(con, in_schema (&quot;pesticides&quot;, &quot;analyse&quot;)) Ici la table analyse n’est pas chargée dans l’environnement R, R s’est juste connecté à la base de données. On peut réaliser des opérations sur la table analyse avec du code R très simplement. Par exemple pour filtrer sur les analyses relatives au Glyphosate : analyse_db &lt;- filter(analyse_db, code_parametre == 1506) Attention, ce code ne touche pas la base de donnée, il n’est pas exécuté. Pour l’exécuter, il faut par exemple afficher la table. analyse_db Même une fois le code exécuté, cette base n’est pas encore un dataframe. Pour importer la table, on utilise la fonction collect() analyse_db &lt;- collect(analyse_db) Cette approche est à conseiller sur d’importantes bases de données, et sans dimension spatiale, car {dbplyr} ne sait pas encore lire ce type de variable (ce qui ne saurait tarder). 4.6 Lire des données du webservice Insee L’Insee met à disposition un webservice d’accès (API) à des données de référence sous le format sdmx. Le package {rsdmx} permet de se connecter directement à ces données. Deux approches sont possibles. La première permet d’accéder à une série particulière. url &lt;- &quot;https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/001564471&quot; datainsee &lt;- as.data.frame(readSDMX(url)) # Encoding(levels(datainsee$TITLE_FR)) &lt;- &quot;UTF-8&quot; Cette approche permet également de télécharger plusieurs séries en une seule requête. Par exemple : nous téléchargeons l’ensemble des données sur les créations et défaillances d’entreprises pour les secteurs de la construction et de l’immobilier sur les Pays de la Loire. url &lt;- &quot;https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/001564471+001564503+001564799+001564823+001582441+001582578+001582597+001582745+001656155+001656161+001655989+001655995&quot; datainsee &lt;- as.data.frame(readSDMX(url)) L’autre approche permet de télécharger un ensemble de données d’une thématique appelé dataflow. Ici, par exemple, on télécharge l’ensemble des données relatives à la construction neuve : url &lt;- &quot;https://bdm.insee.fr/series/sdmx/data/CONSTRUCTION-LOGEMENTS&quot; datainsee &lt;- as.data.frame(readSDMX(url)) "],["manipuler-des-données.html", "Chapitre 5 Manipuler des données 5.1 Les principes des fonctions de {dplyr} 5.2 Présentation des données 5.3 Chargement des données 5.4 Les verbes clefs de {dplyr} pour manipuler une table 5.5 La boîte à outils pour créer et modifier des variables avec R 5.6 Aggréger des données : summarise() 5.7 Aggréger des données par dimension : group_by() 5.8 Le pipe 5.9 La magie des opérations groupées 5.10 Les armes non conventionnelles de la préparation des donnéees", " Chapitre 5 Manipuler des données 5.1 Les principes des fonctions de {dplyr} Le but de {dplyr} est d’identifier et de rassembler dans un seul package les outils de manipulation de données les plus importantes pour l’analyse des données. Ce package rassemble donc des fonctions correspondant à un ensemble d’opérations élémentaires (ou verbes) qui permettent de : Sélectionner un ensemble de variables : select() Sélectionner un ensemble de lignes : filter() Ajouter/modifier/renommer des variables : mutate() ou rename() Produire des statistiques aggrégées sur les dimensions d’une table : summarise() Trier une table : arrange() Manipuler plusieurs tables : left_join(), right_join(), full_join(), inner_join()… D’appliquer cela sur des données, quel que soit leur format : data frames, data.table, base de données sql, big data… D’appliquer cela en articulation avec group_by() qui change la façon d’interpréter chaque fonction : d’une interprétation globale sur l’ensemble d’une table, on passe alors à une approche groupe par groupe : chaque groupe étant défini par un ensemble des modalités des variables définies dans l’instruction group_by(). 5.2 Présentation des données On va travailler sur ce module principalement à partir des données sitadel en date réelle estimée (permis de construire) et à partir des données de qualité des eaux de surface. 5.3 Chargement des données load(file = &quot;extdata/FormationPreparationDesDonnees.RData&quot;) 5.4 Les verbes clefs de {dplyr} pour manipuler une table 5.4.1 Sélectionner des variables : select() Nous allons ici sélectionner un ensemble de variables de la table des prélèvements. prelevementb &lt;- select( prelevement, date_prelevement, code_prelevement, code_reseau, code_station ) datatable(head(prelevementb)) prelevementb &lt;- select(prelevement, -commentaire) names(prelevementb) ## [1] &quot;code_prelevement&quot; &quot;code_intervenant&quot; &quot;code_reseau&quot; &quot;code_station&quot; ## [5] &quot;date_prelevement&quot; &quot;code_support&quot; select() possède ce qu’on appelle des helpers qui permettent de gagner du temps dans l’écriture de notre select. A partir du moment où les conventions de nommage sont correctement effectuées, cela permet de gagner également en reproductibilité d’une année sur l’autre. Exemple : sélectionner toutes les variables qui commencent par “code_” : prelevementb &lt;- select(prelevement, starts_with(&quot;code_&quot;)) Exemple : sélectionner les variables dont les noms sont contenus dans un vecteur de chaînes de caractères : mes_variables &lt;- c(&quot;code_prelevement&quot;, &quot;code_intervenant&quot;, &quot;code_reseau&quot;, &quot;date_prelevement&quot;) prelevementb &lt;- select(prelevement, one_of(mes_variables)) 5.4.2 Trier une table : arrange() prelevementb &lt;- arrange(prelevementb, date_prelevement) 5.4.3 Renommer une variable : rename() prelevementb &lt;- rename(prelevementb, date_p = date_prelevement) On peut aussi directement renommer une variable dans l’opération select() prelevementb &lt;- select(prelevement, date_p = date_prelevement, code_prelevement, code_reseau, code_station) 5.4.4 Filtrer une table : filter() On va ici récupérer les analyses produites par l’ARS ars &lt;- filter(prelevement, code_reseau == &quot;ARS&quot;) L’exemple ci-dessus n’exerce un filtre que sur une condition unique. Pour des conditions cumulatives (toutes les conditions doivent être remplies), le “&amp;” ou la “,” ars &lt;- filter(prelevement, code_reseau == &quot;ARS&quot;, code_intervenant == &quot;44&quot;) Pour des conditions non cumulatives (au moins une des conditions doit être remplie), le “|” ars &lt;- filter(prelevement, code_reseau == &quot;ARS&quot; | code_reseau == &quot;FREDON&quot;) Si une condition non cumulative s’applique sur une même variable, privilégier un test de sélection dans une liste avec le %in% ars &lt;- filter(prelevement, code_reseau %in% c(&quot;ARS&quot;, &quot;FREDON&quot;)) Pour sélectionner des observations qui ne répondent pas à la condition, le ! (la négation d’un test) Toutes les observations ayant été réalisées par un autre réseau que l’ARS : non_ars &lt;- filter(prelevement, code_reseau != &quot;ARS&quot;) Toutes les observations ayant été réalisées par un autre réseau que l’ARS ou FREDON : ni_ars_ni_fredon &lt;- filter(prelevement, !(code_reseau %in% c(&quot;ARS&quot;, &quot;FREDON&quot;))) 5.4.5 Modifier/ajouter une variable : mutate() mutate() est le verbe qui permet la transformation d’une variable existante ou la création d’une nouvelle variable dans le jeu de données. Création de nouvelles variables : prelevementb &lt;- mutate(prelevementb, code_prelevement_caract = as.character(code_prelevement), code_reseau_fact = as.factor(code_reseau) ) Modification de variables existantes : prelevementb &lt;- mutate(prelevementb, code_prelevement = as.character(code_prelevement), code_reseau = as.factor(code_reseau) ) mutate() possède une variante, transmute(), qui fonctionne de la même façon, mais ne conserve que les variables modifiées ou créées par le verbe. 5.4.6 Extraire un vecteur : pull() pull() permet d’extraire sous forme de vecteur une variable d’un dataframe. stations_de_la_table_prelevement &lt;- pull(prelevement, code_station) stations_de_la_table_prelevement &lt;- unique(stations_de_la_table_prelevement) 5.5 La boîte à outils pour créer et modifier des variables avec R 5.5.1 Manipuler des variables numériques Vous pouvez utiliser beaucoup de fonctions pour créer des variables avec mutate() : les opérations arithmétiques : +,-,*,/,^ ; arithmétique modulaire : %/% (division entière) et %% (le reste), où x == y * (x %/% y) + (x %% y) ; logarithmes : log(), log2(), log10() ; navigations entre les lignes : lead() et lag() qui permettent d’avoir accès à la valeur suivante et précédente d’une variable. a &lt;- data.frame(x=sample(1:10)) b &lt;- mutate(a, lagx = lag(x), leadx = lead(x), lag2x = lag(x, n = 2), lead2x = lead(x, n = 2)) datatable(b) opérations cumulatives ou glissantes : R fournit des fonctions pour obtenir opérations cumulatives les somme, produit, minimum et maximum cumulés, dplyr fournit l’équivalent pour les moyennes : cumsum(), cumprod(), cummin(), cummax(), cummean() Pour appliquer des opérations glissantes, on peut soit créer l’opération avec l’instruction lag(), soit exploiter le package RcppRoll qui permet d’exploiter des fonctions prédéfinies. Exemple de somme glissante sur un pas de 2 observations. a &lt;- data.frame(x = sample(1:10)) b &lt;- mutate(a, cumsumx = cumsum(x), rollsumrx = roll_sumr(x, n = 2)) datatable(b) Attention aux différences entre roll_sum() et roll_sumr(). Contrairement à roll_sum(), la fonction roll_sumr() fait en sorte d’obtenir un vecteur de même dimension que l’entrée : a$x ## [1] 1 5 6 3 4 2 7 10 8 9 rollsumrx &lt;- roll_sumr(a$x, n=2) rollsumx &lt;- roll_sum(a$x, n=2) length(rollsumrx) == length(a$x) ## [1] TRUE length(rollsumx) == length(a$x) ## [1] FALSE Aussi dans le cadre d’opérations sur les dataframes, roll_sum() ne fonctionnera pas. b &lt;- mutate(a, cumsumx = cumsum(x), rollsumx = roll_sum(x, n=2)) Comparaisons logiques : &lt;, &lt;=, &gt;, &gt;=, != Rangs : min_rank() devrait être la plus utile, il existe aussi notamment row_number(), dense_rank(), percent_rank(), cume_dist(), ntile(). coalesce(x, y) : permet de remplacer les valeurs manquantes de x par celle de y variable = ifelse(condition(x), valeursioui, valeursinon) permet d’affecter valeursi ou valeursinon à variable en fonction du fait que x répond à condition. Exemple : création d’une variable résultat pour savoir si les résultats de nos analyses sont bons, ou non. analyseb &lt;- mutate(analyse, resultat_ok = ifelse(code_remarque %in% c(1, 2, 7, 10), yes = TRUE, no = FALSE)) qui peut se résumer, lorsque yes = TRUE et no = FALSE, à : analyseb &lt;- mutate(analyse, resultat_ok = code_remarque %in% c(1, 2, 7, 10)) case_when() permet d’étendre la logique de ifelse() à des cas plus complexes. Les conditions mises dans un case_when() ne sont pas exclusives. De ce fait, il faut pouvoir déterminer l’ordre d’évaluation des conditions qui y sont posées. Cet ordre s’effectue de bas en haut, c’est à dire que la dernière condition évaluée (celle qui primera sur toutes les autres) sera la première à écrire. Exemple: On va ici calculer des seuils fictifs sur les analyses. analyseb &lt;- mutate(analyse, classe_resultat_analyse = case_when( resultat_analyse == 0 ~ &quot;1&quot;, resultat_analyse &lt;= 0.001 ~ &quot;2&quot;, resultat_analyse &lt;= 0.01 ~ &quot;3&quot;, resultat_analyse &lt;= 0.1 ~ &quot;4&quot;, resultat_analyse &gt; 0.1 ~ &quot;5&quot;, TRUE ~ &quot;&quot; )) 5.5.2 Exercice 1 : Les données mensuelles sitadel cf. package d’exercices {savoirfR} À partir du fichier sitadel de février 2017 (ROES_201702.xls), produire un dataframe sit_52_ind contenant pour la région Pays-de-la-Loire (code région 52), pour chaque mois et pour les logements individuels (definis par la somme des logements individuels purs et individuels groupés : i_AUT = ip_AUT + ig_AUT) : le cumul des autorisations sur 12 mois glissants (i_AUT_cum12) ; le taux d’évolution du cumul sur 12 mois (i_AUT_cum_evo, en %) ; la part de ce cumul dans celui de l’ensemble des logements autorisés (log_AUT, en %). 5.5.3 Manipuler des dates Parmi l’ensemble des manipulations de variables, celle des dates et des heures est toujours une affaire complexe. Le framework tidyverse propose le package {lubridate} qui permet de gérer ces informations de façon cohérente. gestion des dates : dmy(&quot;jeudi 21 novembre 2020&quot;) dmy(&quot;21112020&quot;) ymd(&quot;20201121&quot;) gestion des dates/heures : dmy_hms(&quot;mardi 21 novembre 2020 9:30:00&quot;) now() combien de jours avant Noël ? annee_en_cours &lt;- year(today()) prochain_noel &lt;- paste(&quot;25 décembre&quot;, annee_en_cours) prochain_noel dmy(prochain_noel) - today() le jour de la semaine d’une date : wday(dmy(&quot;19012038&quot;), label = TRUE) Les fonctions make_date() et make_datetime() vous permettent de transformer un ensemble de variables en un format date ou date - heure. C’est par exemple utile lorsque l’on a des variables séparées pour l’année, le mois et le jour. 5.5.3.1 Exercice 2 : les dates Convertir les colonnes de la table exercice au format date (quand c’est pertinent). 5.5.4 Manipuler des chaînes de caractères Le package {stringr} compile l’ensemble des fonctions de manipulation de chaînes de caractère utiles sur ce type de données. On peut diviser les manipulations de chaînes de caractères en 4 catégories : manipulations des caractères eux-mêmes, gestion des espaces, opérations liées à la langue, manipulations de “pattern,” notamment des expressions régulières. 5.5.4.1 Manipulations sur les caractères Obtenir la longueur d’une chaîne avec str_length() : library(stringr) str_length(&quot;abc&quot;) ## [1] 3 Extraire une chaîne de caractères avec str_sub() str_sub() prend 3 arguments : une chaîne de caractère, une position de début, une position de fin. Les positions peuvent être positives, et dans ce cas, on compte à partir de la gauche, ou négatives, et dans ce cas on compte à partir de la droite. a &lt;- data.frame(x = c(&quot; libeatg&quot;, &quot;delivo y&quot;)) b &lt;- mutate(a, pos3a4 = str_sub(string = x, start = 3, end = 4), pos3a2avtlafin = str_sub(string = x, start = 3, end = -2)) datatable(b) str_sub() peut être utilisé pour remplacer un caractère str_sub(a$x, start = 6, end = 9) &lt;-&quot;rer&quot; a$x ## [1] &quot; liberer&quot; &quot;delivrer&quot; Si on souhaite réaliser ce genre d’opération dans le cadre d’un mutate, il faut utiliser une fonction dite “pipe-operator-friendly,” par exemple stri_sub_replace() du package {stringi} # install.packages(&quot;stringi&quot;) library(stringi) a &lt;- data.frame(x = c(&quot; libeatg&quot;, &quot;delivo y&quot;)) b &lt;- mutate(a, y=stri_sub_replace(str=x, from=6, to=9, value = &quot;rer&quot;)) datatable(b) 5.5.4.2 Gestion des espaces La fonction str_pad() permet de compléter une chaîne de caractère pour qu’elle atteigne une taille fixe. Le cas typique d’usage est la gestion des codes communes Insee. code_insee &lt;- 1001 str_pad(code_insee, 5, pad = &quot;0&quot;) ## [1] &quot;01001&quot; On peut choisir de compléter à gauche, à droite, et on peut choisir le “pad.” Par défaut, celui-ci est l’espace. La fonction inverse de str_pad() est str_trim() qui permet de supprimer les espaces aux extrémités de notre chaîne de caractères. proust &lt;- &quot; Les paradoxes d&#39;aujourd&#39;hui sont les préjugés de demain. &quot; str_trim(proust) ## [1] &quot;Les paradoxes d&#39;aujourd&#39;hui sont les préjugés de demain.&quot; str_trim(proust, side = &quot;left&quot;) ## [1] &quot;Les paradoxes d&#39;aujourd&#39;hui sont les préjugés de demain. &quot; Les expressions régulières permettent la détection de “patterns” sur des chaînes de caractères. Par exemple “^” sert à indiquer que la chaîne de caractère recherchée doit se trouver au début de la chaîne examinée. Au contraire, “$” sert à indiquer que la chaîne de caractère recherchée doit se trouver à la fin. a &lt;- data.frame(txt = c(&quot;vélo&quot;, &quot;train&quot;, &quot;voilier&quot;, &quot;bus&quot;, &quot;avion&quot;, &quot;tram&quot;, &quot;trottinette&quot;)) b &lt;- mutate(a, tr_au_debut = str_detect(string = txt, pattern = &quot;^tr&quot;)) b ## txt tr_au_debut ## 1 vélo FALSE ## 2 train TRUE ## 3 voilier FALSE ## 4 bus FALSE ## 5 avion FALSE ## 6 tram TRUE ## 7 trottinette TRUE filter(b, tr_au_debut) ## txt tr_au_debut ## 1 train TRUE ## 2 tram TRUE ## 3 trottinette TRUE filter(a, str_detect(string = txt, pattern = &quot;n$&quot;)) ## txt ## 1 train ## 2 avion 5.5.4.3 Opérations liées à la langue Ces différentes fonctions ne donneront pas le même résultat en fonction de la langue par défaut utilisée. La gestion des majuscules/minuscules : proust &lt;- &quot;Les paradoxes d&#39;aujourd&#39;hui sont LES préjugés de Demain.&quot; str_to_upper(proust) ## [1] &quot;LES PARADOXES D&#39;AUJOURD&#39;HUI SONT LES PRÉJUGÉS DE DEMAIN.&quot; str_to_lower(proust) ## [1] &quot;les paradoxes d&#39;aujourd&#39;hui sont les préjugés de demain.&quot; str_to_title(proust) ## [1] &quot;Les Paradoxes D&#39;aujourd&#39;hui Sont Les Préjugés De Demain.&quot; La gestion de l’ordre, str_sort() et str_order() : a &lt;- data.frame(x = c(&quot;y&quot;, &quot;i&quot;, &quot;k&quot;)) mutate(a, en_ordre = str_sort(x), selon_position = str_order(x)) ## x en_ordre selon_position ## 1 y i 2 ## 2 i k 3 ## 3 k y 1 Suppression des accents (base::iconv) : proust2 &lt;- &quot;Les paradoxes d&#39;aujourd&#39;hui sont les préjugés de demain ; et ça c&#39;est embêtant&quot; iconv(proust2, to = &quot;ASCII//TRANSLIT&quot;) ## [1] &quot;Les paradoxes d&#39;aujourd&#39;hui sont les prejuges de demain ; et ca c&#39;est embetant&quot; Avec un humour quelque peu discutable, un petit aide-mémoire illustré, assez visuel, est proposé par Lise Vaudor ici. 5.5.5 Manipuler des variables factorielles ( = qualitatives ou catégorielles) Les facteurs (ou factors, an anglais) sont un type de vecteur géré nativement par R qui permettent de gérer les variables qualitatives ou catégorielles. Les facteurs sont souvent mis en regard des données labellisées utilisées dans d’autres logiciels statistiques. Les facteurs possèdent un attribut appelé niveaux (levels, en anglais) qui contient l’ensemble des valeurs qui peuvent être prises par les éléments du vecteur. Les fonctions du module {forcats} permettent de modifier les modalités d’une variable factorielle, notamment : changer les modalités des facteurs et/ou leur ordre, regrouper des modalités. On va ici utiliser la fonction fct_infreq(), pour modifier le tri des stations en fonction de leur fréquence d’apparition dans la table “prelevement.” {forcats} permet beaucoup d’autres possibilités de tri : tri manue des facteurs avec fct_relevel() ; en fonction de la valeur d’une autre variable avec fct_reorder(); en fonction de l’ordre d’apparition des modalités avec fct_inorder(). Consulter la documentation du package {forcats} pour voir toutes les possibilités très riches de ce module. En quoi ces fonctions sont utiles ? Elles permettent notamment : lorsqu’on fait des graphiques, d’afficher les occurences les plus importantes d’abord ; de lier l’ordre d’une variable en fonction d’une autre (par exemple les code Insee des communes en fonction des régions). Exemple : ordonner les modalités d’un facteur pour améliorer l’aspect d’un graphique library(ggplot2) library(forcats) data &lt;- data.frame(num = c(1, 8, 4, 3, 6, 7, 5, 2, 11, 3), cat = c(letters[1:10])) ggplot(data, aes(x = cat, num)) + geom_bar(stat = &quot;identity&quot;) + xlab(label = &quot;Facteur&quot;) + ylab(label = &quot;Valeur&quot;) ggplot(data, aes(x = fct_reorder(cat, -num), num)) + geom_bar (stat = &quot;identity&quot;) + xlab(label = &quot;Facteur ordonné&quot;) + ylab(label = &quot;Valeur&quot;) 5.6 Aggréger des données : summarise() La fonction summarise() permet d’aggréger des données, en appliquant une fonction sur les variables pour construire une statistique sur les observations de la table. summarise() est une fonction dite de “résumé.” À l’inverse de mutate(), quand une fonction summarise est appelée, elle retourne une seule information. La moyenne, la variance, l’effectif… sont des informations qui condensent la variable étudiée en une seule information. La syntaxe de summarise est classique. Le resultat est un dataframe. summarise(exercice, mesure_moyenne = mean(resultat_analyse, na.rm = T)) On peut calculer plusieurs statistiques sur une aggrégation summarise(exercice, mesure_moyenne = mean(resultat_analyse, na.rm = T), mesure_total = sum(resultat_analyse, na.rm = T) ) 5.6.1 Quelques fonctions d’aggrégations utiles compter : n() sommer : sum() compter des valeurs non manquantes sum(!is.na()) moyenne : mean(), moyenne pondérée : weighted.mean() écart-type : sd() médiane : median(), quantile : quantile(.,quantile) minimum : min(), maximum : max() position : first(), nth(., position), last() 5.7 Aggréger des données par dimension : group_by() Summarise est utile, mais la plupart du temps, nous avons besoin non pas d’aggréger des données d’une table entière, mais de construire des aggrégations sur des sous-ensembles : par année, département… La fonction group_by() va permettre d’éclater notre table en fonction de dimensions de celle-ci. Ainsi, si on veut construire des statistiques agrégées non sur l’ensemble de la table, mais pour chacune des modalités d’une ou de plusieurs variables de la table. Il faut deux étapes : utiliser prélablement la fonction group_by() pour définir les variables sur lesquelles on souhaite aggréger les données, utiliser summarise() ou sur la table en sortie de l’étape précédente. Découper un jeu de données pour réaliser des opérations sur chacun des sous-ensembles afin de les restituer ensuite de façon organisée est appelée stratégie du split – apply – combine schématiquement, c’est cette opération qui est réalisée par dplyr dès qu’un group_by() est introduit sur une table. Exemple pour calculer les statistiques précédentes par mois : exercice &lt;- mutate(exercice, annee = year(date_prelevement)) paran &lt;- group_by(exercice, annee) summarise (paran, mesure_moyenne = mean(resultat_analyse, na.rm = T), mesure_total = sum(resultat_analyse, na.rm = T)) ## # A tibble: 26 x 3 ## annee mesure_moyenne mesure_total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1991 0.0981 4.32 ## 2 1992 0.137 8.33 ## 3 1993 0.123 6.14 ## 4 1994 0.0684 4.72 ## 5 1995 0.0803 6.99 ## 6 1996 0.0915 6.86 ## 7 1997 0.0529 5.14 ## 8 1998 0.131 46.5 ## 9 1999 0.0547 89.7 ## 10 2000 0.118 191. ## # … with 16 more rows Pour reprendre des traitements “table entière,” il faut mettre fin au group_by() par un ungroup() 5.8 Le pipe Le pipe est la fonction qui va vous permettre d’écrire votre code de façon plus lisible pour vous et les utilisateurs. Comment ? En se rapprochant de l’usage usuel en grammaire. verbe(sujet,complement) devient sujet %&gt;% verbe(complement) Quand on enchaîne plusieurs verbes, l’avantage devient encore plus évident : verbe2(verbe1(sujet,complement1),complement2) devient sujet %&gt;% verbe1(complement1) %&gt;% verbe2(complement2) En reprenant l’exemple précédent, sans passer par les étapes intermédiaires, le code aurait cette tête : summarise ( group_by ( mutate ( exercice, annee = year (date_prelevement) ), annee ), mesure_moyenne = mean (resultat_analyse, na.rm = T), mesure_total = sum (resultat_analyse, na.rm = T) ) ## # A tibble: 26 x 3 ## annee mesure_moyenne mesure_total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1991 0.0981 4.32 ## 2 1992 0.137 8.33 ## 3 1993 0.123 6.14 ## 4 1994 0.0684 4.72 ## 5 1995 0.0803 6.99 ## 6 1996 0.0915 6.86 ## 7 1997 0.0529 5.14 ## 8 1998 0.131 46.5 ## 9 1999 0.0547 89.7 ## 10 2000 0.118 191. ## # … with 16 more rows Avec l’utilisation du pipe (raccourci clavier CTrl + Maj + M), il devient : exercice %&gt;% mutate(annee = year(date_prelevement)) %&gt;% group_by(annee) %&gt;% summarise(mesure_moyenne = mean (resultat_analyse, na.rm = T), mesure_total = sum (resultat_analyse, na.rm = T)) ## # A tibble: 26 x 3 ## annee mesure_moyenne mesure_total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1991 0.0981 4.32 ## 2 1992 0.137 8.33 ## 3 1993 0.123 6.14 ## 4 1994 0.0684 4.72 ## 5 1995 0.0803 6.99 ## 6 1996 0.0915 6.86 ## 7 1997 0.0529 5.14 ## 8 1998 0.131 46.5 ## 9 1999 0.0547 89.7 ## 10 2000 0.118 191. ## # … with 16 more rows 5.9 La magie des opérations groupées L’opération group_by() que nous venons de voir est très utile pour les aggrégations, mais elle peut aussi servir pour créer des variables ou filtrer une table, puisque group_by() permet de traiter notre table en entrée comme autant de tables séparées par les modalités des variables de regroupement. 5.9.1 Exercice 3 A partir des données “sitadel” (chargées dans l’exercice 1), effectuer les opérations suivantes en utilisant l’opérateur %&gt;% : effectuer les mêmes calculs que ceux réalisés sur la région 52, mais sur chacune des régions –&gt; à stocker dans ‘sit_ind’ calculer les aggrégations par année civile pour chacune des régions, puis leur taux d’évolution d’une année sur l’autre, exemple : (val2015-val2014)/val2014 –&gt; à stocker dans ‘sit_annuel’ 5.9.2 Exercice 4 Sur les données “FormationPreparationDesDonnées.RData,” table “exercice” : calculer le taux de quantification pour chaque molécule et chacune des année : chaque molécule est identifiée par son code_parametre, le taux de quantification est le nombre de fois qu’une molécule est retrouvée (code_remarque = 1) sur le nombre de fois où elle a été cherchée (code_remarque = 1, 2, 7 ou 10). Pour cela : créer la variable “annee” ; créer la variable de comptage des présences pour chaque analyse (1=présent, 0=absent) ; créer la variable de comptage des recherches pour chaque analyse (1=recherchée, 0=non recherchée) ; pour chaque combinaison annee x code_parametre, calculer le taux de quantification. Trouver pour chaque station, sur l’année 2016, le prélèvement pour lequel la concentration cumulée, toutes substances confondues, est la plus élevée (~ le prélèvement le plus pollué). Pour cela : filtrer les concentrations quantifiées (code_remarque=1) et l’année 2016 ; sommer les concentrations (resultat_analyse) par combinaison code_station x code_prelevement ; ne conserver que le prélèvement avec le concentration maximale. 5.10 Les armes non conventionnelles de la préparation des donnéees Nous venons de voir les principaux verbes de manipulation d’une table de dplyr. Ces verbes acquièrent encore plus de puissance quand ils sont appelés avec les fonctions accross() et/ou where(). 5.10.1 Les select helpers Repéter des opérations de nettoyage ou de typage sur les différentes variables d’un jeu de données peut s’avérer fastidieux lorsque l’on a à écrire les opérations variable par variable. La fonction select() propose cinq manières différentes de désigner les variables à sélectionner. Nous avons vu la première et la plus intuitive, qui est de nommer les variables une à une. On peut également utiliser les : qui permettent de sélectionner une liste de variables consécutives. On peut également désigner les variables à sélectionner en fonction de leur position : select(exercice, code_analyse, code_laboratoire, code_prelevement, code_parametre, code_fraction_analysee, resultat_analyse, code_remarque) %&gt;% names() ## [1] &quot;code_analyse&quot; &quot;code_laboratoire&quot; &quot;code_prelevement&quot; ## [4] &quot;code_parametre&quot; &quot;code_fraction_analysee&quot; &quot;resultat_analyse&quot; ## [7] &quot;code_remarque&quot; select(exercice, code_analyse:code_remarque) %&gt;% names() ## [1] &quot;code_analyse&quot; &quot;code_laboratoire&quot; &quot;code_prelevement&quot; ## [4] &quot;code_parametre&quot; &quot;code_fraction_analysee&quot; &quot;resultat_analyse&quot; ## [7] &quot;code_remarque&quot; select(exercice, -c(code_analyse:code_remarque)) %&gt;% names() ## [1] &quot;limite_detection&quot; &quot;limite_quantification&quot; &quot;code_intervenant&quot; ## [4] &quot;code_reseau&quot; &quot;code_station&quot; &quot;date_prelevement&quot; ## [7] &quot;code_support&quot; &quot;commentaire&quot; &quot;libelle_station&quot; ## [10] &quot;date_creation&quot; &quot;source&quot; &quot;code_masse_eau&quot; ## [13] &quot;code_entite_hydro&quot; &quot;code_troncon_hydro&quot; &quot;code_commune&quot; ## [16] &quot;the_geom&quot; &quot;annee&quot; select(exercice, 1:7) %&gt;% names() ## [1] &quot;code_analyse&quot; &quot;code_laboratoire&quot; &quot;code_prelevement&quot; ## [4] &quot;code_parametre&quot; &quot;code_fraction_analysee&quot; &quot;resultat_analyse&quot; ## [7] &quot;code_remarque&quot; select(exercice, -c(1:7)) %&gt;% names() ## [1] &quot;limite_detection&quot; &quot;limite_quantification&quot; &quot;code_intervenant&quot; ## [4] &quot;code_reseau&quot; &quot;code_station&quot; &quot;date_prelevement&quot; ## [7] &quot;code_support&quot; &quot;commentaire&quot; &quot;libelle_station&quot; ## [10] &quot;date_creation&quot; &quot;source&quot; &quot;code_masse_eau&quot; ## [13] &quot;code_entite_hydro&quot; &quot;code_troncon_hydro&quot; &quot;code_commune&quot; ## [16] &quot;the_geom&quot; &quot;annee&quot; Sélectionner les variables en fonction de leur position peut sembler séduisant, mais attention aux problèmes de reproductibilité que cela peut poser si le jeu de données en entrée bouge un peu entre deux millésimes. On peut également sélectionner des variables selon des conditions sur leur nom. Par exemple, on peut selectionner les variables dont le nom commence par “date,” ou se termine par “station,” ou contient “prel” ou en fonction d’une expression régulière comme “m.n” (le nom contient un “m” suivi d’un caractère suivi d’un “n.” select(exercice, starts_with(&quot;date&quot;)) %&gt;% names() ## [1] &quot;date_prelevement&quot; &quot;date_creation&quot; select(exercice, ends_with(&quot;station&quot;)) %&gt;% names() ## [1] &quot;code_station&quot; &quot;libelle_station&quot; select(exercice, contains(&quot;prel&quot;)) %&gt;% names() ## [1] &quot;code_prelevement&quot; &quot;date_prelevement&quot; select(exercice, matches(&quot;m.n&quot;)) %&gt;% names() ## [1] &quot;code_prelevement&quot; &quot;date_prelevement&quot; &quot;commentaire&quot; &quot;code_commune&quot; On peut également sélectionner des variables selon des conditions sur leur type, avec la fonction where(). Par exemple, sélectionner toutes les variables numériques ou toutes les variables de type caractère. select(exercice, where(is.numeric)) %&gt;% names() ## [1] &quot;code_analyse&quot; &quot;code_laboratoire&quot; &quot;code_prelevement&quot; ## [4] &quot;code_parametre&quot; &quot;code_fraction_analysee&quot; &quot;resultat_analyse&quot; ## [7] &quot;code_remarque&quot; &quot;limite_detection&quot; &quot;limite_quantification&quot; ## [10] &quot;code_intervenant&quot; &quot;code_support&quot; &quot;annee&quot; select(exercice, where(is.character)) %&gt;% names() ## [1] &quot;code_reseau&quot; &quot;code_station&quot; &quot;date_prelevement&quot; ## [4] &quot;commentaire&quot; &quot;libelle_station&quot; &quot;date_creation&quot; ## [7] &quot;source&quot; &quot;code_masse_eau&quot; &quot;code_entite_hydro&quot; ## [10] &quot;code_troncon_hydro&quot; &quot;code_commune&quot; On peut enfin sélectionner des variables en combinant les moyens détaillés ci-avant et en recourant aux opérateurs boléens : ! (negation), &amp; (et), | (ou). select(exercice, 1:7 &amp; starts_with(&quot;code&quot;)) %&gt;% names() ## [1] &quot;code_analyse&quot; &quot;code_laboratoire&quot; &quot;code_prelevement&quot; ## [4] &quot;code_parametre&quot; &quot;code_fraction_analysee&quot; &quot;code_remarque&quot; select(exercice, starts_with(&quot;date&quot;) &amp; !where(is.Date)) %&gt;% names() ## [1] &quot;date_prelevement&quot; &quot;date_creation&quot; 5.10.2 Utiliser les select helpers avec les autres verbes du tidyverse 5.10.2.1 rename() et rename_with() Lorsqu’on souhaite renommer les variable une à une, la fonction rename() fonctionne de la même manière que select() : mon_df_renomme &lt;- rename(mon_dataframe, nouveau_nom1 = ancien_nom1, nouveau_nom2 = ancien_nom2) Si l’on souhaite recourir aux select helpers, il faut utiliser rename_with(), avec la synthaxe rename_with(.data= mon_df, .fn= ma_fonction_de_renommage, .cols= les_variables_a_renommer). Exemple avec la fonction toupper() qui passe les chaînes de caractères en majuscules. rename_with(station, toupper, starts_with(&quot;code&quot;)) %&gt;% names() ## [1] &quot;CODE_STATION&quot; &quot;libelle_station&quot; &quot;date_creation&quot; ## [4] &quot;source&quot; &quot;CODE_MASSE_EAU&quot; &quot;CODE_ENTITE_HYDRO&quot; ## [7] &quot;CODE_TRONCON_HYDRO&quot; &quot;CODE_COMMUNE&quot; &quot;the_geom&quot; Si la fonction de renommage est plus complexe qu’un simple mot, il faut recourir au pronom .x et au ~ pour la définir. Exemple avec la fonction str_sub() de {stringr} vue précédemment : rename_with(exercice, ~ str_sub(.x, start = 5, end = str_length(.x)), starts_with(&quot;code&quot;)) %&gt;% names() ## [1] &quot;_analyse&quot; &quot;_laboratoire&quot; &quot;_prelevement&quot; ## [4] &quot;_parametre&quot; &quot;_fraction_analysee&quot; &quot;resultat_analyse&quot; ## [7] &quot;_remarque&quot; &quot;limite_detection&quot; &quot;limite_quantification&quot; ## [10] &quot;_intervenant&quot; &quot;_reseau&quot; &quot;_station&quot; ## [13] &quot;date_prelevement&quot; &quot;_support&quot; &quot;commentaire&quot; ## [16] &quot;libelle_station&quot; &quot;date_creation&quot; &quot;source&quot; ## [19] &quot;_masse_eau&quot; &quot;_entite_hydro&quot; &quot;_troncon_hydro&quot; ## [22] &quot;_commune&quot; &quot;the_geom&quot; &quot;annee&quot; 5.10.3 filter(), mutate(), group_by(), summarise(), arrange(), transmute()… Les autres verbes de {dplyr} ont besoin de la fonction across() pour fonctionner avec les select helpers. Comme pour rename_with(), les fonctions complexes sont à déclarer avec le ~ et le pronom .x. On peut en désigner plusieurs ou leur fournir un nom qui servira de suffixe aux noms des variables calculées, en passant la ou les fonctions dans une liste : .fn=list(suffixe1 = ma_fonction1, suffixe2 = ma_fonction2). La syntaxe générale devient : monverbe(.data, across(mesvariables, malistedefonctions), across(mesvariables2, malistedefonctions2)) filter(parametre, across(starts_with(&quot;date&quot;), ~ .x &gt; &quot;2015-01-01&quot;)) %&gt;% select(1:7) ## code_parametre nom_parametre statut_parametre ## 1 7748 cyfluf\\xe9namide Valid\\xe9 ## 2 7801 Cyprosulfamide Valid\\xe9 ## 3 7782 Desm\\xe9thyl-chlortoluron Valid\\xe9 ## 4 7783 Haloxyfop m\\xe9thyl Valid\\xe9 ## date_creation_parametre date_maj_parametre auteur_parametre ## 1 2015-02-13 2015-02-13 CARSO-LSEHL ## 2 2015-04-30 2015-06-10 AERM ## 3 2015-03-10 2015-03-27 INOVALYS Nantes ## 4 2015-03-10 2015-03-27 INOVALYS ## libelle_court_parametre ## 1 cyfluf\\xe9nam ## 2 Cyprsulfmd ## 3 Desmetchlo ## 4 HaloxyMeth mutate(exercice, across(starts_with(&quot;code&quot;) &amp; where(is.numeric), as.factor), across(starts_with(&quot;date&quot;), as.Date)) %&gt;% slice(1:100) %&gt;% datatable() summarise(parametre, across(starts_with(&quot;code&quot;), n_distinct)) ## code_parametre code_unite_reference code_cas_substance_chimique code_fonction ## 1 659 3 646 23 ## code_famille ## 1 68 group_by(prelevement, across(code_intervenant:code_station)) %&gt;% summarise(across(everything(), list(nb = n_distinct))) ## # A tibble: 823 x 7 ## # Groups: code_intervenant, code_reseau [12] ## code_intervenant code_reseau code_station code_prelevemen… date_prelevemen… ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 44 ARS 044000001 66 66 ## 2 44 ARS 044000044 8 8 ## 3 44 ARS 044000045 6 6 ## 4 44 ARS 044000046 6 6 ## 5 44 ARS 044000047 4 4 ## 6 44 ARS 044000048 6 6 ## 7 44 ARS 044000070 7 7 ## 8 44 ARS 044000071 6 6 ## 9 44 ARS 044000076 7 7 ## 10 44 ARS 044000077 6 6 ## # … with 813 more rows, and 2 more variables: code_support_nb &lt;int&gt;, ## # commentaire_nb &lt;int&gt; Exemple sur l’exercice sur les données sitadel. sitadel &lt;- read_excel(&quot;extdata/ROES_201702.xls&quot;, &quot;AUT_REG&quot;) %&gt;% group_by(REG) %&gt;% mutate(across(where(is.numeric), list(cumul12 = ~ roll_sumr(.x, n = 12))), across(ends_with(&quot;cumul12&quot;), list(evo = ~ 100 * .x / lag (.x, 12) - 100, part = ~ 100 *.x / log_AUT_cumul12))) datatable(sitadel) "],["manipuler-plusieurs-tables.html", "Chapitre 6 Manipuler plusieurs tables 6.1 Exercice 5", " Chapitre 6 Manipuler plusieurs tables Le package {dplyr} possède également plusieurs fonctions permettant de travailler sur deux tables. On va pouvoir regrouper ces fonctions en plusieurs catégories de manipulations : pour fusionner des informations de deux tables entre elles : jointures transformantes, pour sélectionner des observations d’une table en fonction de celles présentes dans une autre table : jointures filtrantes, pour traiter deux tables ayant les mêmes colonnes et sélectionner sur celles-ci des observations de l’une et l’autre : opérations ensemblistes, des manipulations visant à additionner deux tables ensembles : assemblages. 6.1 Exercice 5 reconstituer le dataframe exercice à partir des données contenues dans les tables analyse, prelevement et station (jointures), calculer le nombre d’analyses réalisées sur des molécules (code_parametre) présentes dans le référentiel parametre, produire une liste des code_parametre associés à des analyses mais absents du référentiel, produire une table des analyses “orphelines,” c’est-à-dire qui ne correspondent pas à un prélèvement. "],["structurer-ses-tables.html", "Chapitre 7 Structurer ses tables 7.1 Pourquoi se pencher sur la structuration des tables ? 7.2 Les deux fonctions clefs de {tidyr}", " Chapitre 7 Structurer ses tables 7.1 Pourquoi se pencher sur la structuration des tables ? Pour bien manipuler des données, leur structuration est fondamentale. Il faut bien savoir ce qu’est : une ligne de notre table, une colonne de notre table. Sur une table non aggrégée (un répertoire, une table d’enquête…), la structuration naturelle est une ligne par observation (un individu, une entreprise…), une colonne par variable (âge, taille…) sur cette observation. Mais dès qu’on aggrège une telle table pour construire des tables structurées par dimensions d’analyse et indicateurs, se pose toujours la question de savoir ce qu’on va considérer comme des dimensions et comme des indicateurs. Le standard tidy data définit 3 principes pour des données propres : chaque variable est une colonne, chaque observation est une ligne, les unités d’observations différentes sont stockées dans des tables différentes. Le respect de ces règles va nous amener parfois à devoir changer la définition des lignes et colonnes de nos tables en entrée. Ci-dessous un exemple simple : la population estimée par département et genre en 2019. Ce fichier est un extrait d’un tableur mis à disposition par l’Insee. estim_pop &lt;- read_excel(&#39;extdata/estim-pop-dep-sexe-gca-2019.xls&#39;) estim_pop ## # A tibble: 104 x 20 ## dep lib_dep Ensemble_019ans Ensemble_2039ans Ensemble_4059ans ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Ain 167720 150949 179476 ## 2 02 Aisne 131435 115046 137405 ## 3 03 Allier 67628 61986 87232 ## 4 04 Alpes-… 33883 30028 43039 ## 5 05 Hautes… 30518 28633 37887 ## 6 06 Alpes-… 228072 237427 282270 ## 7 07 Ardèche 71385 62186 88572 ## 8 08 Ardenn… 61006 56583 71821 ## 9 09 Ariège 31143 28962 41017 ## 10 10 Aube 74510 69537 78475 ## # … with 94 more rows, and 15 more variables: Ensemble_6074ans &lt;dbl&gt;, ## # Ensemble_75ansetplus &lt;dbl&gt;, Ensemble_Total &lt;dbl&gt;, Homme_019ans &lt;dbl&gt;, ## # Homme_2039ans &lt;dbl&gt;, Homme_4059ans &lt;dbl&gt;, Homme_6074ans &lt;dbl&gt;, ## # Homme_75ansetplus &lt;dbl&gt;, Homme_Total &lt;dbl&gt;, Femme_019ans &lt;dbl&gt;, ## # Femme_2039ans &lt;dbl&gt;, Femme_4059ans &lt;dbl&gt;, Femme_6074ans &lt;dbl&gt;, ## # Femme_75ansetplus &lt;dbl&gt;, Femme_Total &lt;dbl&gt; En quoi ce fichier n’est pas tidy ? On retrouve 4 variables dans notre fichier : le territoire, le genre, l’âge et la population, et nos colonnes ne correspondent pas à ces variables. Quel serait la version tidy de notre fichier ? ## # A tibble: 1,872 x 5 ## dep lib_dep genre age nombre_individus ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 01 Ain Ensemble 019ans 167720 ## 2 01 Ain Ensemble 2039ans 150949 ## 3 01 Ain Ensemble 4059ans 179476 ## 4 01 Ain Ensemble 6074ans 102788 ## 5 01 Ain Ensemble 75ansetplus 52755 ## 6 01 Ain Ensemble Total 653688 ## 7 01 Ain Homme 019ans 86359 ## 8 01 Ain Homme 2039ans 75242 ## 9 01 Ain Homme 4059ans 89278 ## 10 01 Ain Homme 6074ans 49523 ## # … with 1,862 more rows Comment passer facilement d’un format non tidy à un format tidy ? C’est là qu’intervient le package {tidyr}. 7.2 Les deux fonctions clefs de {tidyr} pivot.longer() permet d’empiler plusieurs colonnes (correspondant à des variables quantitatives). Elles sont repérées par création d’une variable qualitative, à partir de leurs noms. Le résultat est une table au format long. pivot.wider() fait l’inverse. Cette fonction crée autant de colonnes qu’il y a de modalités d’une variable qualitative, en remplissant chacune par le contenu d’une variable numérique. Le résultat est une table au format large. Pour avoir un apperçu illustré de ces fonctions, voir cette animation Reprenons notre table Insee d’estimation de population. Comment faire pour passer cette table dans le format tidy ? Première étape, retrouvons notre colonne population. Pour cela, il nous faut passer notre table au format long, grace à pivot_longer(). estim_pop_tidy &lt;- read_excel(&#39;extdata/estim-pop-dep-sexe-gca-2019.xls&#39;) %&gt;% pivot_longer(-c(dep,lib_dep), values_to = &quot;nombre_individus&quot;, names_to = &quot;genre_age&quot;) Si nous voulions retrouver le format large, nous pourrions utiliser pivot_wider() estim_pop_nontidy &lt;- estim_pop_tidy %&gt;% pivot_wider(names_from = genre_age, values_from = nombre_individus) Nous n’avons pas encore retrouvé nos deux variables genre et age, mais une seule variable mélange les deux. Pour cela, nous pouvons utiliser separate() du package {tidyr}. estim_pop_tidy &lt;- estim_pop_tidy %&gt;% separate(genre_age, sep = &quot;_&quot;, into = c(&quot;genre&quot;,&quot;age&quot;)) Mais pivot_longer() permet d’aller encore plus loin en spécifiant sur nos colonnes un moyen de distinguer nos deux variables directement avec l’argument names_sep. estim_pop_tidy &lt;- read_excel(&#39;extdata/estim-pop-dep-sexe-gca-2019.xls&#39;) %&gt;% pivot_longer(-c(dep, lib_dep), names_sep = &quot;_&quot;, names_to = c(&quot;genre&quot;, &quot;age&quot;), values_to = &quot;nombre_individus&quot;) Et pivot_wider() permet également d’utiliser deux variables pour définir les modalités à convertir en colonnes. estim_pop_nontidy &lt;- estim_pop_tidy %&gt;% pivot_wider(names_from = c(genre,age), values_from = nombre_individus) Vous retrouverez une introduction complète à {tidyr} dans un article très bien fait de la documentation du package (en anglais). {tidyr} permet également de transformer des données sous forme de listes en dataframe tidy très simplement. "],["exercice-6-les-données-majic.html", "Chapitre 8 Exercice 6 : les données majic", " Chapitre 8 Exercice 6 : les données majic A partir des tables fournies dans le fichier majic.RData issues des fichiers fonciers et du recensement de la population, calculer un indicateur d’étalement urbain entre 2009 et 2014 à la commune et à l’epci sur la région Pays de la Loire. La méthode utilisée sera celle du CEREMA. On peut consulter le rapport ici. Le référentiel des communes a changé sur la période, dans un seul sens : il y a eu des fusions. La table com2017 permet de rattacher toute commune ayant existé sur la région à sa commune de rattachement dans la carte communale 2017. Les surfaces artificialisées se calculent comme cela à partir de la typologie d’occupation du sol de majic : \\(SA=dcnt07+dcnt09+ dcnt10+dcnt11+dcnt12+dcnt13\\) Deux indices à calculer : un indice d’étalement urbain simple \\(I_e = \\dfrac{Evolution\\;de\\;la\\;surface\\;artificialisée} {Evolution\\;de\\;la\\;population}\\) un indice d’étalement urbain avancé en classes : "],["aller-plus-loin.html", "Chapitre 9 Aller plus loin", " Chapitre 9 Aller plus loin Quelques références : R for data science : http://r4ds.had.co.nz/transform.html {dplyr}, Introduction : https://dplyr.tidyverse.org/articles/dplyr.html {dplyr}, manipulation de deux tables : https://dplyr.tidyverse.org/articles/two-table.html {tidyr} : https://tidyr.tidyverse.org/ {tidyr}, fonctions pivot : https://tidyr.tidyverse.org/articles/pivot.html Aide mémoire de Rstudio sur {dplyr} et {tidyr} (assez ancien) : https://www.rstudio.com/wp-content/uploads/2016/01/data-wrangling-french.pdf Si vous préférez vous mettre à {data.table} https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf "]]
